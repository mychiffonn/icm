## Replication of Internal Coherence Maximization (ICM)

Task description [here](https://praxis-research.org/sprints/unsupervised-elicitation)

> We seek to elicit specific concepts or skills from a pretrained model without any supervision, thus bypassing the limitations of human supervision. Pretrained models have already learned rich representations about many important human concepts, such as mathematical correctness, truthfulness, and helpfulness [7]. We should not need to teach LMs much about these concepts in post-training—instead, we can just “elicit” them from LMs

- What critique did you find (feel free to briefly mention other critiques you considered)? Why is it important?
- How would you address this issue? What would be your first test to reduce your uncertainty? What would you do with more time?

- What sampling strategy was used?
- More critically, one important implactions of

when used to replace human supervision,
elicit human concepts by mutual predictability
what about long-tail concepts that are not easily predictable from each other, but are relevant to certain demographics?
